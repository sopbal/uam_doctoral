{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a random forrest classifier for endolysin prediction \n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path \n",
    "from random import shuffle\n",
    "from typing import Callable, Union, List, Dict, Tuple, Any, Hashable\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# ML model architectures available for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, PairwiseKernel, Matern, RationalQuadratic, ExpSineSquared, WhiteKernel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class ENDOLYSORFOREST():\n",
    "    def __init__(self, classifier, featurefile, labelfile):\n",
    "        #use the following parameters:\n",
    "        #For MLPC: hidden_layer_sizes=200, random_state= 1964, max_iter = 250\n",
    "        #For RF and GP: n_jobs = 1, random_state= 1964\n",
    "        #For the SVC: cache_size = 3000, probability = True\n",
    "        self.classifier = classifier(hidden_layer_sizes=200, random_state= 1964, max_iter = 250)\n",
    "        \n",
    "    def split_data(self, featurefile):\n",
    "        #instead of a singular file you can submit a list of files, which enables combining features from different methods \n",
    "        if len(featurefile) == 1:\n",
    "            for f in featurefile:\n",
    "                endofeatures = pd.read_csv(f, index_col = 0, sep ='\\t')\n",
    "                trainfile, testfile = train_test_split(endofeatures, test_size=0.2, random_state=25)\n",
    "                getmetricslist = trainfile.columns.tolist()\n",
    "        elif len(featurefile) > 1:\n",
    "            dfs = []\n",
    "            for f in featurefile:\n",
    "                df = pd.read_csv(f, index_col = 0, sep ='\\t')\n",
    "                dfs.append(df)\n",
    "            endofeatures = pd.concat(dfs, axis =1, join = 'inner')\n",
    "            trainfile, testfile = train_test_split(endofeatures, test_size = 0.2, random_state = 25)\n",
    "            getmetricslist = trainfile.columns.tolist()\n",
    "        else:\n",
    "            print('Empty file list')\n",
    "        return trainfile, testfile, getmetricslist\n",
    "    \n",
    "    def match_labels(self, testfile, labelfile):\n",
    "        labeldf = pd.read_csv(labelfile, header = None, sep = '\\t')\n",
    "        labeldf.columns = ['id', 'yesno']\n",
    "        mylist = []\n",
    "        for index, row in testfile.iterrows():\n",
    "            for idx, r in labeldf.iterrows():\n",
    "                if index == r['id']:\n",
    "                    sublist = [r['id'], r['yesno']]\n",
    "                    mylist.append(sublist)\n",
    "        mydf = pd.DataFrame(mylist)\n",
    "        mydf.columns = ['id', 'yesno']\n",
    "        return mydf\n",
    "            \n",
    "    def fit_model(self, trainfile, labelfile):\n",
    "        #convert the representation to a tuple with vector, lable pairs\n",
    "        mytable = pd.read_csv(labelfile, header = None, sep = '\\t')\n",
    "        mytable.columns = ['id', 'yesno']\n",
    "        labels = pd.Series(mytable.yesno.values,index=mytable.id).to_dict()\n",
    "        labeled_vectors = []\n",
    "        for index, row in trainfile.iterrows(): \n",
    "            label = labels[index]\n",
    "            labeled_vectors.append((np.array(row), label))\n",
    "        \n",
    "        #shuffle the data to prevent clumping of positives, which might confuse the model\n",
    "        shuffle(labeled_vectors)\n",
    "        \n",
    "        datalen = len(labeled_vectors)\n",
    "        vectors = np.zeros(datalen, dtype = object)\n",
    "        labels = np.zeros(datalen)\n",
    "        for i, (x, y) in enumerate(labeled_vectors):\n",
    "            vectors[i], labels[i] = x, y\n",
    "\n",
    "        vectors, labels = make_classification(n_samples = 150, n_features = 54, random_state= 1964) #change the type of samples and features \n",
    "        self.classifier.fit(vectors, labels)\n",
    "    \n",
    "    def test_model(self, testfile, mydf):\n",
    "        \"check if a protein is an endolysin. testing the model\"\n",
    "        testdata = []\n",
    "        labels1 = mydf['yesno'].to_numpy()\n",
    "        for index, row in testfile.iterrows():\n",
    "            testdata.append(np.array(row))\n",
    "        print(len(testdata))\n",
    "        print(len(labels1))\n",
    "        predictions = self.classifier.predict(testdata)\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(labels1, predictions)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(labels1, predictions)\n",
    "        aucval = metrics.auc(fpr, tpr)\n",
    "        print(\"Accuracy:\", metrics.accuracy_score(labels1, predictions))\n",
    "        print(\"Sensitivity:\", metrics.recall_score(labels1, predictions))\n",
    "        print(\"Roc_AUC_score:\", metrics.roc_auc_score(labels1, predictions))\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"Thresholds:\", thresholds)\n",
    "        print(\"ROC_curve:\", fpr, tpr)\n",
    "        print(\"AUC:\", aucval)\n",
    "        print(\"Report:\", classification_report(labels1, predictions, target_names= ['no', 'yes'], digits = 4, zero_division = 1))\n",
    "        \n",
    "        #Plot the precision recall curve\n",
    "        \n",
    "        display = metrics._plot.precision_recall_curve.PrecisionRecallDisplay.from_predictions(labels1, predictions)\n",
    "        _ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n",
    "        \n",
    "    def draw_plot(self, testfile, mydf):\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        testdata = []\n",
    "        labels1 = mydf['yesno'].to_numpy()\n",
    "        for index, row in testfile.iterrows():\n",
    "            testdata.append(np.array(row))\n",
    "        predictions = self.classifier.predict(testdata)\n",
    "        \n",
    "        n_classes = 2\n",
    "\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = metrics.roc_curve(labels1, predictions)\n",
    "            roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(labels1.ravel(), predictions.ravel())\n",
    "        roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(\n",
    "            fpr[1],\n",
    "            tpr[1],\n",
    "            color=\"darkorange\",\n",
    "            lw=lw,\n",
    "            label=\"ROC curve (area = %0.2f)\" % roc_auc[1],\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Receiver operating characteristic example\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ENDOLYSORFOREST(MLPClassifier, ['a'], 'b')\n",
    "\n",
    "#w celu wytrenowania modelu wywolywalam kolejne funkcje w klasie "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
